{
    "contents" : "# Doodles\n\nfoo = function(x) {\n  x + 1\n}\n\n\n\n\nbar <- function(a, b) {\n  if (a > b) {\n    a**b\n  }\n  else if (a == b) {\n    a + b\n  }\n  else {\n    a - b\n  }\n}\n\n\n\na <- seq(3, 7)\nbaz <- function(x) {\n  d <- 3\n  for (i in x) {\n    d <- d + i\n    # print(d)\n  }\n  return(d)\n}\n\n\nbaz(a)\n\n\n\na <- seq(3, 7)\nbaz.1 <- function(x) {\n  d <- 3\n  for (i in x) {\n    d + i\n    print(d + i)\n  }\n  return(d + i)\n}\n\n\nbaz.1(a)\n\n\n\n\n\nj <- function(x) {\n  q <- 6\n  if (x %% 2 == 0) {\n    q + x\n  }\n  else {\n    q - x\n  }\n}\n\n\nj(5)\n\n\n\n\n\n\n\n\nobjs <- mget(ls(\"package:base\"), inherits = TRUE)\nfuns <- Filter(is.function, objs)\n\n\nn.formals <- function(x) {\n  length(formals(x))\n}\n\n\nn.formals <- function(l, f) {\n  for (f in l) {\n    length(formals(f))\n  }\n}\n\nn.formals <- function(l, f) {\n  for (f in l) {\n    length.formals <- length(formals(f))\n    return(length.formals)\n  }\n}\n\n\n\n\nn.formals(corpus)\n\nmax(n.formals(funs))\n\n\nclass(n.formals(funs))\n\n\nn.formals(funs)\n\nn.formals(funs[[111]])\n\nfuns[[111]]\n\n\n\n\n\n\n\n\n\nf <- function(x) {\n  x$a <- 2\n  x$a\n}\n\nx <- list(a = 1, b = 3)\n\n\ny <- f(x)\ny\n\n\n\n\n\nm <- function(a) {\n  l <- function(x) x * 2\n  l(a) + 1\n}\n\n\n\n\nn <- function(x) {x / 2}\no <- function() {\n  n <- 10\n  n(n)\n}\n\n\na <- 3\nj <- function() {\n  if (!exists(\"a\")) {\n    a <- 1\n  } else {\n    a <- a + 1\n  }\n  print(a)\n}\n\n\nc <- 10\nc(c = 20)\n\n\n\n\n\n\n`(` <- function(x) {\n  if (is.numeric(x) && runif(1) < 0.1) {\n    x + 1\n  }\n  else {\n    x\n  }\n}\n\nevil.1 <- function(e1) {\n  if (is.numeric(e1) && runif(1) < 0.1) {\n    e1 + 1\n  } else {\n    e1\n  }\n}\n\n\nreplicate(50, (1 + 2))\n\n\nreplicate(evil(50, (1 + 2)))\n\n\n\n\n\n\n\nl <- c(1, 4, 5, 7)\n\nsapply(l, function(x) x + 1)\n\n\n\n\nsapply(1:3, function(x, y) mean(y[,x]), y=m)\n\n\nl <- c(1, 4, 5, 7)\n\nsapply(2:4, function(x) y[values(x)*2], y=l)\n\n\n\na <- function(q) {\n  for (i in q) {\n    # b <- c(2:4)\n    if (2 <= i <=4) {\n      i*2\n    } else {\n      break\n      }\n    }\n}\n\nb <- a(l)\n\n\nrm(a,l,b)\nl <- c(1, 4, 5, 7)\na <- function(q) {\n  for (i in q) {\n    if (i %% 2 == 0) {\n      i*2\n      print(i*2)\n    } else {\n      i+2\n      print(i+2)\n    }\n  }\n}\n\na <- function(q) {\n  m <- c(2:3)\n  for (i in q[m]) {\n    if (i %% 2 == 0) {\n      i*2\n      print(i*2)\n    } else {\n      i+2\n      print(i+2)\n    }\n  }\n}\n\n\n\nl <- c(1, 4, 5, 7)\n\nsapply(2:4, function(x) y[values(x)*2], y=l)\n\n# This does what the sapply above was supposed to do\na <- function(q) {\n  m <- c(2:3)\n  for (i in q[m]) {\n    i*2\n    print(i*2)\n  }\n}\nb <- a(l)\nb\n\n\n\n\nx = 0\nfor (k in seq(100))\n{\n  if (k %% 2 == 0) { next } ## Skip even numbers, but keep looping.\n  if (x >= 50) { break } ## Quit looping when the sum exceeds 50.\n  x = x + k\n}\n\n\n\n\n\n\n\n\nm <- seq(1:18)\nn <- seq(3, 54, by=3)\n\no <- cbind(m, n)\n\n\np <- as.matrix(c(1:5), byrow=T)\n\n\n\n\nx <- cbind(a = 1:3, pi = pi) # simple matrix with dimnames\nrownames(x) <- c('foo', 'bar', 'baz')\nattributes(x)\n\n\n\n\n\n\na <- seq(2,37, by=3)\n\nas.null(a[4:5])\n\nsapply(a, function (x) x^2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nfun <- function(foo, bar=3) {\n  baz <- foo^bar\n  print(baz)\n}\n\nfun(2)\n\n\n\n\nf <- function(abcdef, bcde1, bcde2) {\n  l <- list(a = abcdef, b1 = bcde1, b2 = bcde2)\n  # print(l)\n}\nstr(f(1, 2, 3))\n\nstr(f(2, 3, a = 15))\n\n\n\n\nf <- function(x) {\n  10\n}\n\nf()\n\n\n\n\n\n\n\n\nlst <- seq(5, 15, 2)\n\n\nz <- function(l) {\n  a <- 4\n  for (i in l) {\n    a <- a + i\n    print(a)\n  }\n}\n\nz(lst)\n\n\n\n\n\ntxt <- \"Four score and seven years ago our fathers brought forth\"\n\n\n\nall.f <- function(t) {\n  grep(t, 'f')\n}\n\nall.f(txt)\n\n\ngrep('s', txt)\n\n\ntxt2 <- c(\"Four\", \"score\", \"and\", \"seven\")\nb <- grep('and', txt2)\ntxt2[b]\n\n\n\n\ntxt <- c(\"arm\",\"foot\",\"lefroo\", \"bafoobar\")\nif(length(i <- grep(\"foo\", txt)))\n  cat(\"'foo' appears at least once in\\n\\t\", txt, \"\\n\")\ni # 2 and 4\ntxt[i]\n\n\n\n\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract(shopping_list, \"\\\\d\")\nstr_extract(shopping_list, \"[a-z]+\")\n\nstr_extract_all(shopping_list, \"[a-z]+\")\nstr_extract_all(shopping_list, \"\\\\b[a-z]+\\\\b\")\nstr_extract_all(shopping_list, \"\\\\d\")\n\n\n\n\n\n\n\n# random forest stuff\n# from: http://www.bios.unc.edu/~dzeng/BIOS740/randomforest.pdf\n\n# 1. Draw ntree bootstrap samples from the original data.\n# 2. For each of the bootstrap samples, grow an unpruned\n# classification or regression tree\n# BUT at each node, rather\n# than choosing the best split among all predictors,\n# randomly sample mtry of the predictors\n# and choose the best split from among those variables\n\n# if the DV is a factor, randomForest performs classification; if the response\n# is continuous, randomForest performs regression\n\n# oob = out of bag\n\nlibrary(randomForest)\nlibrary(MASS)\n\ndata(fgl) # load the fgl data from the MASS package\nset.seed(17) # start RNG at this number so we can reproduce the result\n\n# DV = type\nfgl.rf <- randomForest(type ~ ., data = fgl,\n                       mtry = 2, importance = TRUE, # we want to know how important each variable is\n                       do.trace = 100) # output printed for every 100 trees\nprint(fgl.rf)\n\nplot(fgl.rf)\n\n\n\n\n\n\n#### K nearest neighbors ####\n\nlibrary(class)\n\n# target variable = type\n\n# Find the dimensions of our dataframe\ndim(fgl)\n\nhead(fgl)\n\n# Split data into training and test (about 50:50)\n# Use all columns excpet the target one (column 10)\nfgl.train <- fgl[1:100, 1:9]\nfgl.test <- fgl[101:214, 1:9]\n\n\n# get vector of target labels from the target column\nfgl.train.labels <- fgl[1:100, 10]\nfgl.test.labels <- fgl[101:214, 10]\n\n\n# fgl.train is the data frame used to train the model\n# fgl.test is the data frame used to test\n# cl is a vector of the correct classifications of the target training label (so the actual type of thing it is)\n# k is the number of nearest neighbors to consider. Generally the square root of the observations\n# nearest neighbors are determined by Euclidean distance\n\n# what is returned is a vector of the predicted target labels of test set\n# so fgl.pred is approximating the values in fgl.test.labels using what it knows \n# from fgl.train and using the correct answers to the training set in fgl.train.labels\nfgl.pred <- knn(fgl.train, fgl.test, cl=fgl.train.labels, k=10)\n\n\nhead(fgl.pred)\nhead(fgl.train.labels)\n\n\n\n# how well did the model predict the test lables?\nlibrary(gmodels)\nCrossTable(fgl.pred, fgl.test.labels, prop.r=F, prop.t=F, prop.chisq = F)\n\n\n# test vector consisted of 114 data points\n\n\n\n\n\n## ggvis ##\nlibrary(ggvis)\n\nggvis(iris)\n\niris %>% \n  ggvis(~Petal.Length, ~Petal.Width, fill=~Species) %>% \n  layer_points() %>%\n  layer_smooths()\n\n# same as\nlayer_smooths(layer_points(ggvis(~Petal.Length, ~Petal.Width, fill=~Species, data=iris)))\n\n\n# check levels of target factor, Species\nlevels(iris$Species)\n\n# number of species per level in target\ntable(iris$Species)\n# percentage\nround(prop.table(table(iris$Species)) * 100, digits = 1)\n\n\niris.train <- iris[1:100, 1:4]\niris.test <- iris[101:150, 1:4]\n\n\niris.train.labels <- iris[1:100, 5]\niris.test.labels <- iris[101:150, 5]\n\nset.seed(1235)\niris.pred <- knn(train=iris.train, test=iris.test, cl=iris.train.labels, k=7)\n\n\niris.out <- cbind(iris.pred, iris.train.labels)\niris.out\n\n\n\nCrossTable(iris.pred, iris.test.labels, prop.chisq = F)\n\n\n\n\n\n# iris random forest #\n\niris.rf <- randomForest(Species ~ . , data=iris)\n\nprint(iris.rf)\nplot(iris.rf)\n\niris.imp <- importance(iris.rf)\niris.imp\n\n\n\n\n### iris KNN with normed variables ###\n# as per https://www.datacamp.com/community/tutorials/machine-learning-in-r#gs.JIcctJU\n\nnormalize <- function(x) {\n  num <- x - min(x)\n  denom <- max(x) - min(x)\n  return (num/denom)\n}\n\n# norm the data in columns 1 to 4\niris.normed <- as.data.frame(lapply(iris[, 1:4], normalize))\nhead(iris.normed)\n\n# stick the iris species names back on to our datframe\niris.normed <- cbind(iris.normed, iris[,5])\nnames(iris.normed)[5] <- \"Species\"\nhead(iris.normed)\nsummary(iris.normed$Species)\n\n\n# assign rows to training or test at random (so not just first 50 are training and last 100 are test)\n# make a vector the same length as our dataset with a random 1 or 2 assigned to each position based on the split we want\n# 1 = training, 2 = test. Train with 1/3 of data, test with 2/3\nrand.num <- sample(c(1, 2), nrow(iris.normed), replace=T, prob=c((1/3), (2/3)))\n\n\n# don't need to put this column onto data\n# iris.normed <- cbind(iris.normed, iris.samp)\n# names(iris.normed)[6] <- \"randNum\"\n# \n# head(iris.normed)\n\n\n# split dataset into training and test, and take out the target varialbe\n# take the row numbers of all the 1s in the rand.num vector [vector that is separate and apart from our dataframe -- that's why we don't have iris.normed$rand.num)\n# use all columns except the target\niris.n.train <- iris.normed[rand.num==1, 1:4]\niris.n.test <- iris.normed[rand.num==2, 1:4]\n\n# store the target variable in a vector\niris.n.train.labels <- iris.normed[rand.num==1, 5]\niris.n.test.labels <- iris.normed[rand.num==2, 5]\n\n\n# make sure that we have the right split\n# should be about (but not necc exactly) 33-67 split\nnrow(iris.n.train)\nnrow(iris.n.test)\nlength(iris.n.train.labels)\nlength(iris.n.test.labels)\n\n\n# our model\n# uses data frame iris.n.train and correct answer in vector iris.n.train.lables to classify data frame iris.n.test into new vector iris.n.pred\niris.n.pred <- knn(train=iris.n.train, test=iris.n.test, cl=iris.n.train.labels, k=3, prob=T)\n\niris.n.pred\n\n\n# see how well the model did\nCrossTable(iris.n.test.labels, iris.n.pred, prop.chisq = F)\n\n\n\n\n\n\nsamp <- sample(3, 100, replace=T, prob=c(0.1, 0.5, 0.4))\n\nsamp2 <- sample(6:8, 100, replace=T)\n\nsamp.df <- cbind(samp, samp2)\n\nclass(samp.df)\n\nsamp.df <- as.data.frame(samp.df)\n\nnames(samp.df) <- c(\"Samp 1\", \"Samp 2\")\n\nhead(samp.df)\n\nsamp.df.double <- sapply(samp.df, function(x) x*2) # try lapply. Looks different in next line, but end up with same df when make into df\n\nhead(samp.df.double)\n\nsamp.df.double <- as.data.frame(samp.df.double)\n\nhead(samp.df.double)\n\n\nsamp.df.bigger <- as.data.frame(rep(samp.df.double, 2))\n\nhead(samp.df.bigger)\n\ns.4 <- as.data.frame(\n  sapply(samp.df.bigger[, 1:2], function(x) x - 1)\n)\n\n\n\n\n\n\n\n\n\n## SQL ##\n\nlibrary(sqldf)\nlibrary(PASWR)\n\ndata(titanic3, package=\"PASWR\")\ncolnames(titanic3)\nhead(titanic3)\n\n# express this table using sql syntax rather than r\nsqldf('select age, count(*) \n      from titanic3 \n      where age is not null \n      group by age')\n\n\n# can get the same thing with\nlibrary(plyr)\ncount(titanic3, 'age')\n\n\n\n\n\n\n\n\n\n## dplyr stuff ##\n\n\nlibrary(dplyr)\n\ntitanic3$age.count <- length(which(titanic3$age))\n\ndistinct(select\n         (arrange\n         (titanic3, age)))\n\n\nt <- titanic3 %>%\n  group_by(age) %>%\n  # filter(4 > age > 16) %>%\n  # select(plcass, sex, age, fare) %>%\n  arrange(desc(age))\n\nhead(t)\n\n\n\n\n\n\n\n\n\n### PCA ###\n\n\n\n\n\n\n\n\n# Postgres #\n\nlibrary(RPostgreSQL)\n\n# set up driver as postgres\ndrv <- dbDriver(\"PostgreSQL\")\n\n# set connection to our db\ncon <- dbConnect(drv, dbname=\"pullplay_db\", host='localhost', port=5432, user=\"amanda\")\n\n# import tables from db\nstack_left <- dbGetQuery(con, \"SELECT * FROM stack_left\")\nbring_heat <- dbGetQuery(con, \"SELECT * FROM bring_heat\")\nbring_heat_2 <- dbGetQuery(con, \"SELECT * FROM bring_heat_2\") \n# added player 7 and elapsed time to /Desktop/wildfire_stats.csv\n# didn't change headers in csv -- \n# instead used HEADER TRUE in this query:\n# COPY bring_heat_2 FROM '/Users/amanda/Desktop/wildfire_stats.csv' \n# WITH (FORMAT CSV,\n#       DELIMITER ',',\n#       HEADER TRUE,\n#       NULL \"NULL\");\n# had to set datatype of elapsed_time to varchar because postgres complained about null values when it\n# was set to real\n# but now allows us to have null values in player_7 and elapsed_time [with NULL \"NULL\"]\n# as well as to not have to change column names in CSV to exclude spaces [with HEADER TRUE]\n\n\n# remove first line in bring_heat (header repeat)\nbring_heat <- bring_heat[-1, ]\n\n# check variable datatypes\nstr(bring_heat)\n\n# set datatypes\nwant.as.factor <- c('opponent', 'line', 'event_type', 'act', 'passer', 'receiver', 'defender',\n                    'player_0', 'player_1', 'player_2', 'player_3', 'player_4', 'player_5',\n                    'player_6', 'player_7')\n\n\n# lapply(bring_heat[, want.as.factor], factor)\n\n# make_factor <- function (l) {\n#   for (var in l) {\n#     as.factor(var)\n#   }\n# }\n\n\n# make these columns factors\nbring_heat[, want.as.factor] <- data.frame(apply(bring_heat[, want.as.factor], 2, as.factor))\n\n# set scores as numeric\nbring_heat$our_score <- as.numeric(bring_heat$our_score)\nbring_heat$their_score <- as.numeric(bring_heat$their_score)\n\n\n\n# same for bring_heat_2\nbring_heat_2[, want.as.factor] <- data.frame(apply(bring_heat_2[, want.as.factor], 2, as.factor))\n\n# set scores as numeric\nbring_heat_2$our_score <- as.numeric(bring_heat_2$our_score)\nbring_heat_2$their_score <- as.numeric(bring_heat_2$their_score)\n\nstr(bring_heat_2)\n\n\n\n# max scores\nmax(bring_heat$our_score)\nmax(bring_heat$their_score)\n\n\n# which rows had that max score\nwhich(bring_heat$our_score == max(bring_heat$our_score))\n\n# number of Ds by person\nlength(which(bring_heat$act=='D' & bring_heat$defender=='JSS'))\nlength(which(bring_heat$act=='D' & bring_heat$defender=='Cullen'))\nlength(which(bring_heat$act=='D' & bring_heat$defender=='Slymer'))\nlength(which(bring_heat$act=='D' & bring_heat$defender=='Goose'))\n\n# number of throwaways\nlength(which(bring_heat$act=='Throwaway' & bring_heat$passer=='Matzuka'))\n\n\n# who got the most Ds?\nDs_perPlayer <- bring_heat_2 %>%\n  group_by(defender) %>%\n  filter(act == 'D', !is.na(defender), defender != '') %>%\n  select(defender, act, our_score, their_score) %>%\n#   mutate(\n#     mean_our_score = mean(our_score)\n#   ) %>%\n  summarise(\n    blocks = n() \n  ) %>%\n  arrange(desc(blocks)) %>%\n  print(n=nrow(Ds_perPlayer))\n\n\n\n\n\n\n## function to check if packages are masking other packages ##\n# call with amigoingmad()\n\namigoingmad = function(fix = TRUE, package = \"dplyr\", iteration = 0) {\n  if (iteration > 1) {\n    stop(\"Can't fix.\")\n  }\n  conf = unique(conflicts())\n  want_package = paste0(\"package:\", package)\n  conflicts_desired_package = conf[conf %in% ls(want_package)]\n  conflict_envs = sapply(conflicts_desired_package, FUN = function(x) {\n    environmentName(pryr::where(x)) # this is the line with pryr. Tried changing to plyr w/ no luck\n  })\n  is_good = conflict_envs == want_package\n  potentially_bad_confs = conflicts_desired_package[!is_good]\n  potentially_bad_envs = conflict_envs[!is_good]\n  have_to_fix = rep(FALSE, length(potentially_bad_confs))\n  for (i in seq_along(potentially_bad_confs)) {\n    if (!identical(body(get(potentially_bad_confs[i], pos = want_package)), \n                   body(get(potentially_bad_confs[i])))) {\n      have_to_fix[i] = TRUE\n    }\n  }\n  \n  if (any(have_to_fix)) {\n    message(\"The following functions don't have the environment you want.\")\n    print(data.frame(`function` = potentially_bad_confs[have_to_fix], \n                     environment = potentially_bad_envs[have_to_fix]), \n          row.names = F)\n    if (fix) {\n      base::detach(name = want_package, character.only = TRUE)\n      base::library(package, character.only = TRUE)\n      message(\"Tried to fix this, calling myself again to make sure...\")\n      amigoingmad(fix, package, iteration + 1)\n      message(\"Sanity restored!\")\n    }\n  } else if (iteration == 0) {\n    message(\"Everything looks normal. Maybe it's you.\")\n  }\n}\n\n\n\n## other dataframes ##\n\ndat <- data.frame(sex = c(rep(1, 1000), rep(2, 1000)),\n                  treatment = rep(c(1, 2), 1000),\n                  response1 = rnorm(2000, 0, 1),\n                  response2 = rnorm(2000, 0, 1))\n\n## reshape2 still does its thing:\nlibrary(reshape2)\nmelted <- melt(dat, id.vars=c(\"sex\", \"treatment\"))\n\ngrouped <- group_by(melted, sex, treatment)\nsummarise(grouped, mean=mean(value), sd=sd(value))\n\n\n\nir <- group_by(iris, Species)\nir <- summarise(ir,\n                s.w = mean(Sepal.Width)\n)\nir\n\n\n\n### Primary 2016 data ###\n\nprimary_2016 <- dbGetQuery(con, \"SELECT * FROM primary_2016\") \n\nto.factor <- c('state', 'state_abbr', 'county', 'fips_county_code', 'party',\n               'candidate')\n\nprimary_2016[, to.factor] <- data.frame(apply(primary_2016[, to.factor], 2, as.factor))\n\nstr(primary_2016)\n\nlibrary(dplyr)\n# make sure to detach MASS before using dplyr because it will mask select\n\nprimary <- primary_2016 %>%\n  group_by(candidate, state) %>%\n  select(candidate, state, votes, fraction_votes) %>%\n  mutate(\n    avg_votes = mean(votes) # %>%\n  # head(primary) # %>%\n  # primary\n  ) \n\n\n\nprimary <- primary_2016 %>%\n  group_by(state, candidate) %>%\n  filter(candidate %in% c('Bernie Sanders', 'Hillary Clinton', 'Donald Trump')) %>%\n  select(candidate, state, votes, fraction_votes) %>%\n  summarise(\n    avg_votes = mean(votes)\n  ) \nprimary\n\n\n# works\np.spread <- primary %>%\n  spread (\n    key = candidate,\n    value = avg_votes\n  )\np.spread\n\n# works\np.unspread <- p.spread %>%\n  gather (\n    key = candidate,\n    value = avg_votes,\n    -state # everything but state\n  )\np.unspread\n\n\n\n\ndf <- data.frame(x = c(\"a\", \"b\"), y = c(3, 4), z = c(5, 6))\ndf\ndf.s <- df %>% \n  spread (\n  key = x, \n  value = y\n  )\ndf.s\n\ndf.g <- df.s %>%\n  gather (\n  key = x,\n  value = y,\n  a:b\n)\ndf.g\n\ndf %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)\n\n\n\n\n\n\nlibrary(tidyr)\nb.spread <- spread(bring_heat_2, key = \"player\", value = act)\nhead(b.spread)\n\n\nb.spread <- gather(bring_heat_2, role, player, passer:defender)\nhead(b.spread, 50)\n\n\nb.gather <- gather(bring_heat_2, key = name, value = act, player_0:player_7)\nhead(b.gather)\n\n\n\n\nhead(bring_heat_2, 5)\n\n\n\nhead(bring_heat_2)\nb.gather <- gather(bring_heat_2, key = name, value = thing, passer:defender)\nhead(b.gather)\n\n\n\nb2 <- bring_heat_2 %>%\n  select(act:defender)\n\nb2[b2 == ''] <- NA\nhead(b2)\n\n\nstr(b2)\nb3 <- b2\nb3$act <- as.character(b2$act)\nb3$passer <- as.character(b2$passer)\nb3$receiver <- as.character(b2$receiver)\nb3$defender <- as.character(b2$defender)\n\n\n# works\n# can't combine passer, receiver, and defender because passer and receiver\n# are both present in a given row\nb3 <- b2 %>% \n  gather(\n    key = actor,\n    value = name,\n    passer:receiver,\n    na.rm=T\n  ) \ntail(b3, 50)\n\n\n\n\n\n\n\n\nhead(iris)\nhead(gather(iris, key = flower_att, value = measurement, -Species))\n\n\n\n\n### spread ###\n# use when an observation spans multiple rows (df is too long)\n# the values in 'key' get turned into column names and key gets dropped\n\n### gather ###\n# use when column names are values of a variable (df is too wide)\n# you make up new names for both key and value\n# the columns specified in the first argument get dropped and become the values in 'key'\n\n\n\ndf <- data.frame(x = c(\"a\", \"b\"), y = c(3, 4), z = c(5, 6))\ndf\ndf.s <- df %>% \n  spread (\n    key = x, \n    value = y\n  )\ndf.s\n\ndf.g <- df.s %>%\n  gather (\n    key = x,\n    value = y,\n    a:b,\n    factor_key = T\n  )\ndf.g\n\n\n\n\n\nstocks <- data_frame(\n  year   = c(2015, 2015, 2016, 2016),\n  half  = c(   1,    2,     1,    2),\n  return = c(1.88, 0.59, 0.92, 0.17)\n)\n\n\ns2 <- spread(\n  stocks,\n  key = half,\n  value = return\n)\ns2\n\ns3 <- gather(\n  s2,\n  key = half,\n  value = return,\n  - year\n  # 2:3         # using 2:3 does the same thing\n)\ns3\n\n\n\n\n\n\n\n\ns4 <- stocks %>%\n  group_by (\n    year\n  ) %>%\n  summarise (\n    avg_return = mean(return)\n  ) %>%\n  spread (\n    key = year,\n    value = avg_return\n  )\ns4\n\ns5 <- s4 %>%\n  gather(\n    key = year,\n    value = money,\n    1:2\n  )\ns5\n\n\n\ns6 <- stocks %>%\n  spread(\n    key = year,\n    value = return\n  ) %>%\n  gather (\n    -half,\n    key = year,\n    value = return\n  )\ns6\n\n\n\n\nhead(primary_2016)\n\nas_tibble(primary_2016)\n\np2 <- primary_2016 %>%\n  filter (\n    candidate %in% c('Hillary Clinton', 'Donald Trump')\n  ) %>%\n  spread (\n    key = candidate,\n    value = votes\n  ) %>%\n  group_by (\n    state\n  ) %>%\n  summarise (\n    avg_votes = mean(fraction_votes)\n  )\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n\n\n\n\n# load multiple packages\npackages <- c('tibble', 'tidyr', 'dplyr')\n\nlapply(packages, library, character.only = TRUE)\n\n \nlibrary(RPostgreSQL)\n\n# set up driver as postgres\ndrv <- dbDriver(\"PostgreSQL\")\n\n# set connection to our db\ncon <- dbConnect(drv, dbname=\"pullplay_db\", host='localhost', port=5432, user=\"amanda\")\n\n\nprimary_2016 <- dbGetQuery(con, \"SELECT * FROM primary_2016\") \n  \n\nto.factor <- c('state', 'state_abbr', 'county', 'fips_county_code', 'party',\n               'candidate')\n\nprimary_2016[, to.factor] <- data.frame(apply(primary_2016[, to.factor], 2, as.factor))\n\nstr(primary_2016)\n\n\n\np3 <- primary_2016 %>%\n  group_by (\n    state, candidate\n  ) %>%\n  summarise (\n    mean_votes = mean(votes),\n    mean_fract = mean(fraction_votes)\n  ) %>%\n  filter (\n    candidate %in% c('Bernie Sanders', 'Hillary Clinton', 'Donald Trump')\n  ) %>%\n  print(n=10)\n\n\n# get avg total votes per state per candidate that we care about\np4 <- p3 %>%\n  select (\n    -mean_fract        # if don't take out mean_fract, df has to stay in longer format and end up with NAs\n  ) %>%\n  spread (\n    key = candidate,\n    value = mean_votes\n    # drop = F\n  ) %>%\n  print(n=51)\n\n\n\n\nstr(iris)\n  \nhead(iris)\n\n\ni <- iris %>%\n  gather (\n  key = measure,\n  value = measurement,\n  1:4\n  ) %>%\n  group_by(Species, measure) %>%\n  summarise (\n    n(),\n    m = mean(measurement)\n  ) %>%\n  print(n = 10)\n\n\nii <- i %>%\n  spread (\n    key = Species,\n    value = m\n  ) %>%\n  print(n = 10)\n\n\niii <- ii %>%\n  gather (\n    key = species,\n    value = cm,\n    setosa:virginica\n  )  %>%\n  print(n = 10)\n\n\niv <- iii %>%\n  spread (\n    key = measure,\n    value = cm\n  )\n\nv <- ii %>%\n  gather (\n    key = species,\n    value = cm,\n    setosa:virginica\n  ) %>%\n  spread (\n    key = measure,\n    value = cm\n  ) %>%\n  print(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhead(bring_heat_2)\n\n\nbh <- bring_heat_2 \n\nbh[bh == ''] <- NA\nhead(bh)\n\n\nbh2 <- bh %>% \n  select (\n    passer, receiver, defender\n    , act, id\n  ) %>%\n  gather (\n    key = actor,\n    value = name,\n    passer:defender,\n    convert = T,\n    na.rm = T,\n    factor_key = TRUE\n  )\nhead(bh2, 50)\n\ntail(bh2, 50)\n\nhead(bh, 50)\n\n\n\nbh3 <- bh2 %>%\n  group_by (\n    name\n  ) %>%\n  summarise (\n    n(),\n    catches = sum(act == 'Catch'),\n    goals = sum(act == 'Goal'),\n    ds = sum(act == 'D')\n  ) %>% \n  arrange (\n    desc(ds)\n  ) %>%\n  print(n = nrow(bh3))\n\n\n\nbh4 <- bring_heat_2\nbh4 <- bh4[bh4 == ''] <- NA\n\nbh4 <- bring_heat_2 %>%\n  select (\n    act, passer, receiver, defender,\n    our_score, their_score\n  ) %>%\n  mutate (\n    player = gather (\n      key = player,\n      value = act\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## flights\n\n\nflights <- dbGetQuery(con, \"SELECT * FROM flights\") \n\n\nmake.fact <- c('origin', 'origin_city', 'dest', 'dest_city', 'dest_state')\n\nflights[, make.fact] <- data.frame(apply(flights[, make.fact], 2, as.factor))\n\nstr(flights)\n\n\nhead(flights)\n\nmean(flights$weather_del)\n\n\nf <- flights %>%\n  filter (\n    !is.na(weather_del),\n    !is.na(carrier_del)\n  ) %>%\n  # na.omit() %>%\n  group_by (\n    airline_id\n  ) %>%\n  summarise (\n    n = n(),\n    w_del = mean(weather_del),\n    c_del = mean(carrier_del),\n    airTime = mean(air_time)\n  ) %>%\n  print(n = 12)\n\n\n\nff <- f %>%\n  select (\n    airline_id, n\n  ) %>%\n  spread (\n    key = airline_id,\n    value = n\n  )\nff\n\n\nfff <- f %>%\n  mutate (\n    tot_del = w_del + c_del\n  ) %>%\n  arrange (\n    desc(tot_del)\n  )\n\nfff\n\nfv <- fff %>%\n  filter (\n    dense_rank(tot_del) < 5         # compare to min_rank() and row_number\n  )\nfv\n\n\na <- flights %>%\n  tally()\na\n\n\n\n\n\n\nhead(bring_heat_2)\nstr(bring_heat_2)\n\nbring_heat_2$elapsed_time <- as.numeric(bring_heat_2$elapsed_time)\n\nb <- bring_heat_2 %>%\n  group_by(opponent) %>%\n  mutate (\n    run_time = elapsed_time - lag(elapsed_time),\n    perc_change = run_time/elapsed_time\n  ) %>%\n  select(\n    opponent, our_score, their_score, \n    elapsed_time, run_time, perc_change\n  ) %>%\n  print(n = 100)\n\n\n\n\n\n\n\n\n# load in county_facts data from sql\ncounty_facts <- dbGetQuery(con, \"SELECT * FROM county_facts\")\n\nstr(county_facts)\n\nto.fact <- c('area_name', 'state_abbreviation')\n\ncounty_facts[, to.fact] <- data.frame(apply(county_facts[, to.fact], 2, as.factor))\n\nstr(county_facts)\n\nhead(county_facts)\n\n\n\n# take id out of county_facts so join() doesn't get confused\ncounty <- county_facts %>%\n  select (\n    county_code,\n    state_abbreviation, population_2014, \n    female, white, black, hispanic, college,\n    inc_percap, inc_household\n  )\n\n\n# inner join on county code\nelection <- primary_2016 %>%\n  select(\n    fips_county_code,            # again taking id out here\n    state, state_abbr, \n    party, candidate,\n    votes, fraction_votes\n  ) %>%\n  inner_join(county, by = c(\"fips_county_code\" = \"county_code\"))\n\n\nhead(election)\n\n\n\nelect <- election %>%\n  filter (\n    candidate %in% c('Hillary Clinton', 'Donald Trump')\n  ) %>%\n  group_by(state, candidate) %>%\n  summarise(                 # try summarise vs. mutate here. [mutate acts like window function]\n    n.counties = n(),\n    w.b_gap = mean(white - black),        # try taking out the mean function here\n    fr.votes = mean(fraction_votes),\n    percap = mean(inc_percap)\n  ) %>%\n  spread (                   # so value in candidate name columns is the avg fraction of the vote they got per state\n    key = candidate,\n    value = fr.votes\n  ) %>%\n  print(n = nrow(elect))\n\n\n# elect before we spread(). just looking at hillary\ne <- election %>%\n  filter (\n    candidate %in% c('Hillary Clinton')\n  ) %>%\n  group_by(state, candidate) %>%\n  summarise(                 # try summarise vs. mutate here. [mutate acts like window function]\n    n.counties = n(),\n    w.b_gap = mean(white - black),        # try taking out the mean function here\n    fr.votes = mean(fraction_votes),\n    percap = mean(inc_percap)\n  ) %>%\n  print(n = nrow(elect))\n\n\n\nel.mod <- e %>%\n  do (\n    mod = lm(fr.votes ~ w.b_gap*percap, data = .)\n  )\n\n\n\n\n\n\niris <- as_tibble(iris)\n\niris <- iris %>%\n  filter (\n    Species %in% c('versicolor'))\niris\n\ncombo <- election %>%\n  dplyr::filter (\n    candidate %in% c('Hillary Clinton', 'Donald Trump')\n  )\n\n\n# combo <- election %>%\n#   dplyr::filter (\n#     candidate %in% c(!'Bernie Sanders')\n#   )\n# \n# # if filter not working...\n# combo <- combo[!combo$candidate %in% c('Bernie Sanders'), ]\n\n\n\n\n\n\n\n\n\n\n\n# make function to rename candidates to just their last names after spreading\n\n# so instead of\nnames(general.by.state.spread)[names(general.by.state.spread)=='Donald Trump'] <- 'Trump'\nnames(general.by.state.spread)[names(general.by.state.spread)=='Hillary Clinton'] <- 'Clinton'\n\n# want\nrename.cands <- function (dat) {\n  names(dat)[names(dat)=='Donald Trump'] = 'Trump'\n  # names(dat)[names(dat)=='Hillary Clinton'] = 'Clinton'\n  return(names(dat))\n}\n\nrename.cands(general.by.state.spread)\ngeneral.by.state.spread\n\n\n\nrename.date <- function (dat) {\n  names(dat)[names(dat)=='date/time'] = 'date_time'\n  # names(dat)[names(dat)=='Hillary Clinton'] = 'Clinton'\n  return(names(dat))\n}\n\nrename.date(bh2)\nrename.date\n\n\n\n\n# -------------------------------------------\n# experimentation on column headers for wildfire data\n\n# make vector of original column names so can experiment on them\nbh_orig <- bh\nnames(bh_orig)\n\n# experiment on bh2 names\nbh2 <- bh_orig\nnames(bh2)\n\nnames(bh2) <- str_replace_all(names(bh2), \" \", \"_\")\nnames(bh2)\n\nnames(bh2) <- str_replace_all(names(bh2), \"_-_End_of_Point\", \"\")\nnames(bh2)\n\nnames(bh2) <- gsub('_(secs)', '', names(bh2), fixed = TRUE)\nnames(bh2)\n\nrename.date <- function (dat) {\n  names(dat)[names(dat)=='date/time'] = 'date_time'\n  return(names(dat))\n}\n\nrename.date(bh2)\n\n\nnames(bh2) <- tolower(names(bh2))\n\n\n\n# can also just use rename from dplyr\n\nbh <- bh %>% \n  rename(\n    elapsed_time = `elapsed time (secs)`\n  )\n\n#------------------------------------\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1472228565125.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2560589130",
    "id" : "A18E4ECB",
    "lastKnownWriteTime" : 1472233925,
    "path" : "~/Desktop/post_exCog/doodles.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}